Calicia Perea HW3- Machine Learning Report.txtFor the first run of all my models I used:Perceptron:	random_state=42Logistic Regression:	random_state=42, C=0.1, max_iter=10000SVM:	kernel='linear’, random_state=42, C=1.1, max_iter=10000SVM W/ RBF:	random_state=42, kernel='rbf', C=1, gamma=0.001Decision Tree:	random_state=42, max_depth=10, min_samples_split=5KNN:	n_neighbors=5-----Results: ----------I wanted to have a baseline time for what I was running against. Now changing and testing time and accuracy after adding a new hyper-parameter. The baseline testing will be Commented out in my code. The testing will be separate. Bolded are the hyperparameter changed state. -----Tests: ----------Perceptron:	random_state=1	random_state=100Logistic Regression:	random_state=42, C=0.100, max_iter=10000	random_state=42, C=1.1, max_iter=10000SVM:	kernel='linear’, random_state=42, C=1.8, max_iter=10000	kernel='linear’, random_state=42, C=10, max_iter=10000SVM W/ RBF:	random_state=42, kernel='rbf', C=1, gamma=0.01       random_state=42, kernel='rbf', C=1, gamma=1.01Decision Tree:	random_state=42, max_depth=50, min_samples_split=5	random_state=42, max_depth=5, min_samples_split=5KNN:	n_neighbors=20	n_neighbors=150-----Results: ----------Test1:Test2:Between both tests we see that the training time and testing time for each model are significantly different. The time that it takes to train ranged close to both tests even with changing the hyper- parameters. Although the precisions between. Between the two tests the Non-linear SVM RBF showed the precision at 7% with the second and 79% with the first. Meaning my parameters needed to be higher. My first test had multiple precisions at 97%, while in the second test I only had 3 models at 97%.