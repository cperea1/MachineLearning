# -*- coding: utf-8 -*-
"""HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iL3TO3gQLgy2BGFdg7_2TOG9mOx_sbsc
"""

'''
 Calicia Perea 
 HW3 
 Machine Language
 February 22, 2023
  PRE:
  POST:
  time.time() function to get the current time in seconds since the epoch, and then printed the result.
        -Return the time in seconds since the epoch as a floating point number. 

'''
from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC, SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

import time
# 2. Load the digits dataset
# 80:20 split training:testing

digits = datasets.load_digits()
dat = train_test_split(digits.data, digits.target, 
                       train_size=0.8,
                       test_size=0.2,
                       random_state=42)
x_train, x_test, y_train, y_test = dat

# 1. Write classification code by utilizing several scikit-learn classifiers: 
#(i) perceptron
print("\nPerceptron")
begin = time.time()
perceptron = Perceptron(random_state=42)
perceptron.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", perceptron.score(x_train, y_train))
print("Testing precision:", perceptron.score(x_test, y_test))

#(ii) logistic regression,
print("\nLogistic Regression")
begin = time.time()
logreg = LogisticRegression(random_state=42, C=0.1, max_iter=10000)
logreg.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", logreg.score(x_train, y_train))
print("Testing precision:", logreg.score(x_test, y_test))

# (iii) linear support vector machine (SVM), 
print("\nLinear SVM")
begin = time.time()
linearsvm = SVC(kernel='linear',random_state=42, C=1.1, max_iter=10000)
linearsvm.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", linearsvm.score(x_train, y_train))
print("Testing precision:", linearsvm.score(x_test, y_test))


#(iv) non-linear SVM using Radial Basis Func9on (RBF) kernel, 
print("\nNon-linesr SVM with RBF kernel")
begin = time.time()
rbfsvm = SVC(random_state=42, kernel='rbf', C=1, gamma=0.001)
rbfsvm.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", rbfsvm.score(x_train, y_train))
print("Testing precision:", rbfsvm.score(x_test, y_test))


#(v) decision tree,
print("\nDecision Tree")
begin = time.time()
dt = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)
dt.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", dt.score(x_train, y_train))
print("Testing precision:", dt.score(x_test, y_test))


# and (vi) KNN.
print("\nKNN")
begin = time.time()
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
end = time.time()
print("Training time:", end - begin,"sec")
print("Training precision:", knn.score(x_train, y_train))
print("Testing precision:", knn.score(x_test, y_test))